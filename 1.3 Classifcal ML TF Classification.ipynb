{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict the day price direction of Amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./Datasets/Stock Price Direction/AMZN_train.csv\")\n",
    "df_test = pd.read_csv(\"./Datasets/Stock Price Direction/AMZN_test.csv\")\n",
    "df_val= pd.read_csv(\"./Datasets/Stock Price Direction/AMZN_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.927083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>72156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>14700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.760417</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>6106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>5467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>18853200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close    Volume\n",
       "0  1997-05-15  2.437500  2.500000  1.927083  1.958333   1.958333  72156000\n",
       "1  1997-05-16  1.968750  1.979167  1.708333  1.729167   1.729167  14700000\n",
       "2  1997-05-19  1.760417  1.770833  1.625000  1.708333   1.708333   6106800\n",
       "3  1997-05-20  1.729167  1.750000  1.635417  1.635417   1.635417   5467200\n",
       "4  1997-05-21  1.635417  1.645833  1.375000  1.427083   1.427083  18853200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4781 entries, 0 to 4780\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       4781 non-null   object \n",
      " 1   Open       4781 non-null   float64\n",
      " 2   High       4781 non-null   float64\n",
      " 3   Low        4781 non-null   float64\n",
      " 4   Close      4781 non-null   float64\n",
      " 5   Adj Close  4781 non-null   float64\n",
      " 6   Volume     4781 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 261.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4781.000000</td>\n",
       "      <td>4781.000000</td>\n",
       "      <td>4781.000000</td>\n",
       "      <td>4781.000000</td>\n",
       "      <td>4781.000000</td>\n",
       "      <td>4.781000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>127.619845</td>\n",
       "      <td>129.480122</td>\n",
       "      <td>125.697925</td>\n",
       "      <td>127.662449</td>\n",
       "      <td>127.662449</td>\n",
       "      <td>8.225935e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145.693083</td>\n",
       "      <td>147.132537</td>\n",
       "      <td>144.053633</td>\n",
       "      <td>145.677581</td>\n",
       "      <td>145.677581</td>\n",
       "      <td>7.810188e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.406250</td>\n",
       "      <td>1.447917</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>4.872000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.299999</td>\n",
       "      <td>34.849998</td>\n",
       "      <td>33.660000</td>\n",
       "      <td>34.310001</td>\n",
       "      <td>34.310001</td>\n",
       "      <td>4.200900e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.880001</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>60.937500</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>6.200100e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>189.009995</td>\n",
       "      <td>191.600006</td>\n",
       "      <td>186.210007</td>\n",
       "      <td>189.029999</td>\n",
       "      <td>189.029999</td>\n",
       "      <td>9.239900e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>717.380005</td>\n",
       "      <td>722.450012</td>\n",
       "      <td>711.510010</td>\n",
       "      <td>717.929993</td>\n",
       "      <td>717.929993</td>\n",
       "      <td>1.043292e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  4781.000000  4781.000000  4781.000000  4781.000000  4781.000000   \n",
       "mean    127.619845   129.480122   125.697925   127.662449   127.662449   \n",
       "std     145.693083   147.132537   144.053633   145.677581   145.677581   \n",
       "min       1.406250     1.447917     1.312500     1.395833     1.395833   \n",
       "25%      34.299999    34.849998    33.660000    34.310001    34.310001   \n",
       "50%      62.880001    64.750000    60.937500    62.750000    62.750000   \n",
       "75%     189.009995   191.600006   186.210007   189.029999   189.029999   \n",
       "max     717.380005   722.450012   711.510010   717.929993   717.929993   \n",
       "\n",
       "             Volume  \n",
       "count  4.781000e+03  \n",
       "mean   8.225935e+06  \n",
       "std    7.810188e+06  \n",
       "min    4.872000e+05  \n",
       "25%    4.200900e+06  \n",
       "50%    6.200100e+06  \n",
       "75%    9.239900e+06  \n",
       "max    1.043292e+08  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that our data is sorted by date\n",
    "df_train.sort_values(by=\"Date\", inplace=True)\n",
    "df_val.sort_values(by=\"Date\", inplace=True)\n",
    "df_test.sort_values(by=\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that we shift by a period of '-1', this takes the next day's price direction for the current day\n",
    "# a positive period will take the days from the past\n",
    "df_train[\"Target\"] = (df_train[\"Close\"] > df_train[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)\n",
    "df_val[\"Target\"] = (df_val[\"Close\"] > df_val[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)\n",
    "df_test[\"Target\"] = (df_test[\"Close\"] > df_test[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Feature engineering happens after split, to reduce data drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Moving_Average_3\"] = (df_train[\"Close\"] - df_train[\"Open\"]).rolling(window=3, min_periods=1).mean()\n",
    "df_val[\"Moving_Average_3\"] = (df_val[\"Close\"] - df_val[\"Open\"]).rolling(window=3, min_periods=1).mean()\n",
    "df_test[\"Moving_Average_3\"] = (df_test[\"Close\"] - df_test[\"Open\"]).rolling(window=3, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Moving_Average_7\"] = (df_train[\"Close\"] - df_train[\"Open\"]).rolling(window=7, min_periods=1).mean()\n",
    "df_val[\"Moving_Average_7\"] = (df_val[\"Close\"] - df_val[\"Open\"]).rolling(window=7, min_periods=1).mean()\n",
    "df_test[\"Moving_Average_7\"] = (df_test[\"Close\"] - df_test[\"Open\"]).rolling(window=7, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current price direction\n",
    "df_train[\"Today_Direction\"] = df_train[\"Close\"] - df_train[\"Open\"]\n",
    "df_val[\"Today_Direction\"] = df_val[\"Close\"] - df_val[\"Open\"]\n",
    "df_test[\"Today_Direction\"] = df_test[\"Close\"] - df_test[\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price range\n",
    "df_train[\"Price_Range\"] = df_train[\"High\"] - df_train[\"Low\"]\n",
    "df_val[\"Price_Range\"] = df_val[\"High\"] - df_val[\"Low\"]\n",
    "df_test[\"Price_Range\"] = df_test[\"High\"] - df_test[\"Low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>Moving_Average_3</th>\n",
       "      <th>Moving_Average_7</th>\n",
       "      <th>Today_Direction</th>\n",
       "      <th>Price_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>2008-11-14</td>\n",
       "      <td>43.610001</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>11949700</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253335</td>\n",
       "      <td>-0.601429</td>\n",
       "      <td>-1.860001</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>301.940002</td>\n",
       "      <td>307.359985</td>\n",
       "      <td>301.940002</td>\n",
       "      <td>306.540009</td>\n",
       "      <td>306.540009</td>\n",
       "      <td>4003800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436666</td>\n",
       "      <td>-0.705710</td>\n",
       "      <td>4.600007</td>\n",
       "      <td>5.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>2011-09-29</td>\n",
       "      <td>234.169998</td>\n",
       "      <td>234.300003</td>\n",
       "      <td>216.289993</td>\n",
       "      <td>222.440002</td>\n",
       "      <td>222.440002</td>\n",
       "      <td>9378500</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.126663</td>\n",
       "      <td>-2.434283</td>\n",
       "      <td>-11.729996</td>\n",
       "      <td>18.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>46.437500</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>40.437500</td>\n",
       "      <td>48.562500</td>\n",
       "      <td>48.562500</td>\n",
       "      <td>11666600</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-0.580357</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>9.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>289.760010</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>289.760010</td>\n",
       "      <td>295.589996</td>\n",
       "      <td>295.589996</td>\n",
       "      <td>5572600</td>\n",
       "      <td>0</td>\n",
       "      <td>4.253326</td>\n",
       "      <td>2.681423</td>\n",
       "      <td>5.829986</td>\n",
       "      <td>8.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>640.919983</td>\n",
       "      <td>649.989990</td>\n",
       "      <td>622.289978</td>\n",
       "      <td>647.809998</td>\n",
       "      <td>647.809998</td>\n",
       "      <td>7435900</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.243347</td>\n",
       "      <td>-0.264299</td>\n",
       "      <td>6.890015</td>\n",
       "      <td>27.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>259.350006</td>\n",
       "      <td>264.600006</td>\n",
       "      <td>258.029999</td>\n",
       "      <td>263.549988</td>\n",
       "      <td>263.549988</td>\n",
       "      <td>2119100</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.343333</td>\n",
       "      <td>-0.287140</td>\n",
       "      <td>4.199982</td>\n",
       "      <td>6.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1999-07-29</td>\n",
       "      <td>51.187500</td>\n",
       "      <td>52.187500</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>18748000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.841146</td>\n",
       "      <td>-0.713170</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>2.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2008-04-28</td>\n",
       "      <td>80.639999</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>80.120003</td>\n",
       "      <td>81.970001</td>\n",
       "      <td>81.970001</td>\n",
       "      <td>10991900</td>\n",
       "      <td>0</td>\n",
       "      <td>1.453336</td>\n",
       "      <td>1.212857</td>\n",
       "      <td>1.330002</td>\n",
       "      <td>2.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1997-07-02</td>\n",
       "      <td>1.515625</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.588542</td>\n",
       "      <td>1.588542</td>\n",
       "      <td>3882000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "2895  2008-11-14   43.610001   44.500000   41.500000   41.750000   41.750000   \n",
       "4430  2014-12-22  301.940002  307.359985  301.940002  306.540009  306.540009   \n",
       "3618  2011-09-29  234.169998  234.300003  216.289993  222.440002  222.440002   \n",
       "763   2000-05-24   46.437500   49.750000   40.437500   48.562500   48.562500   \n",
       "4392  2014-10-28  289.760010  298.000000  289.760010  295.589996  295.589996   \n",
       "4657  2015-11-16  640.919983  649.989990  622.289978  647.809998  647.809998   \n",
       "4008  2013-04-22  259.350006  264.600006  258.029999  263.549988  263.549988   \n",
       "555   1999-07-29   51.187500   52.187500   50.000000   50.781250   50.781250   \n",
       "2754  2008-04-28   80.639999   82.500000   80.120003   81.970001   81.970001   \n",
       "33    1997-07-02    1.515625    1.593750    1.510417    1.588542    1.588542   \n",
       "\n",
       "        Volume  Target  Moving_Average_3  Moving_Average_7  Today_Direction  \\\n",
       "2895  11949700       0         -0.253335         -0.601429        -1.860001   \n",
       "4430   4003800       0          0.436666         -0.705710         4.600007   \n",
       "3618   9378500       0         -6.126663         -2.434283       -11.729996   \n",
       "763   11666600       0         -0.937500         -0.580357         2.125000   \n",
       "4392   5572600       0          4.253326          2.681423         5.829986   \n",
       "4657   7435900       0         -7.243347         -0.264299         6.890015   \n",
       "4008   2119100       1         -0.343333         -0.287140         4.199982   \n",
       "555   18748000       0         -0.841146         -0.713170        -0.406250   \n",
       "2754  10991900       0          1.453336          1.212857         1.330002   \n",
       "33     3882000       1          0.026042          0.004464         0.072917   \n",
       "\n",
       "      Price_Range  \n",
       "2895     3.000000  \n",
       "4430     5.419983  \n",
       "3618    18.010010  \n",
       "763      9.312500  \n",
       "4392     8.239990  \n",
       "4657    27.700012  \n",
       "4008     6.570007  \n",
       "555      2.187500  \n",
       "2754     2.379997  \n",
       "33       0.083333  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>Moving_Average_3</th>\n",
       "      <th>Moving_Average_7</th>\n",
       "      <th>Today_Direction</th>\n",
       "      <th>Price_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>2008-11-14</td>\n",
       "      <td>43.610001</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>11949700</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253335</td>\n",
       "      <td>-0.601429</td>\n",
       "      <td>-1.860001</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>301.940002</td>\n",
       "      <td>307.359985</td>\n",
       "      <td>301.940002</td>\n",
       "      <td>306.540009</td>\n",
       "      <td>306.540009</td>\n",
       "      <td>4003800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436666</td>\n",
       "      <td>-0.705710</td>\n",
       "      <td>4.600007</td>\n",
       "      <td>5.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>2011-09-29</td>\n",
       "      <td>234.169998</td>\n",
       "      <td>234.300003</td>\n",
       "      <td>216.289993</td>\n",
       "      <td>222.440002</td>\n",
       "      <td>222.440002</td>\n",
       "      <td>9378500</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.126663</td>\n",
       "      <td>-2.434283</td>\n",
       "      <td>-11.729996</td>\n",
       "      <td>18.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>46.437500</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>40.437500</td>\n",
       "      <td>48.562500</td>\n",
       "      <td>48.562500</td>\n",
       "      <td>11666600</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-0.580357</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>9.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>289.760010</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>289.760010</td>\n",
       "      <td>295.589996</td>\n",
       "      <td>295.589996</td>\n",
       "      <td>5572600</td>\n",
       "      <td>0</td>\n",
       "      <td>4.253326</td>\n",
       "      <td>2.681423</td>\n",
       "      <td>5.829986</td>\n",
       "      <td>8.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>640.919983</td>\n",
       "      <td>649.989990</td>\n",
       "      <td>622.289978</td>\n",
       "      <td>647.809998</td>\n",
       "      <td>647.809998</td>\n",
       "      <td>7435900</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.243347</td>\n",
       "      <td>-0.264299</td>\n",
       "      <td>6.890015</td>\n",
       "      <td>27.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>259.350006</td>\n",
       "      <td>264.600006</td>\n",
       "      <td>258.029999</td>\n",
       "      <td>263.549988</td>\n",
       "      <td>263.549988</td>\n",
       "      <td>2119100</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.343333</td>\n",
       "      <td>-0.287140</td>\n",
       "      <td>4.199982</td>\n",
       "      <td>6.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1999-07-29</td>\n",
       "      <td>51.187500</td>\n",
       "      <td>52.187500</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>18748000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.841146</td>\n",
       "      <td>-0.713170</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>2.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2008-04-28</td>\n",
       "      <td>80.639999</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>80.120003</td>\n",
       "      <td>81.970001</td>\n",
       "      <td>81.970001</td>\n",
       "      <td>10991900</td>\n",
       "      <td>0</td>\n",
       "      <td>1.453336</td>\n",
       "      <td>1.212857</td>\n",
       "      <td>1.330002</td>\n",
       "      <td>2.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1997-07-02</td>\n",
       "      <td>1.515625</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.588542</td>\n",
       "      <td>1.588542</td>\n",
       "      <td>3882000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "2895  2008-11-14   43.610001   44.500000   41.500000   41.750000   41.750000   \n",
       "4430  2014-12-22  301.940002  307.359985  301.940002  306.540009  306.540009   \n",
       "3618  2011-09-29  234.169998  234.300003  216.289993  222.440002  222.440002   \n",
       "763   2000-05-24   46.437500   49.750000   40.437500   48.562500   48.562500   \n",
       "4392  2014-10-28  289.760010  298.000000  289.760010  295.589996  295.589996   \n",
       "4657  2015-11-16  640.919983  649.989990  622.289978  647.809998  647.809998   \n",
       "4008  2013-04-22  259.350006  264.600006  258.029999  263.549988  263.549988   \n",
       "555   1999-07-29   51.187500   52.187500   50.000000   50.781250   50.781250   \n",
       "2754  2008-04-28   80.639999   82.500000   80.120003   81.970001   81.970001   \n",
       "33    1997-07-02    1.515625    1.593750    1.510417    1.588542    1.588542   \n",
       "\n",
       "        Volume  Target  Moving_Average_3  Moving_Average_7  Today_Direction  \\\n",
       "2895  11949700       0         -0.253335         -0.601429        -1.860001   \n",
       "4430   4003800       0          0.436666         -0.705710         4.600007   \n",
       "3618   9378500       0         -6.126663         -2.434283       -11.729996   \n",
       "763   11666600       0         -0.937500         -0.580357         2.125000   \n",
       "4392   5572600       0          4.253326          2.681423         5.829986   \n",
       "4657   7435900       0         -7.243347         -0.264299         6.890015   \n",
       "4008   2119100       1         -0.343333         -0.287140         4.199982   \n",
       "555   18748000       0         -0.841146         -0.713170        -0.406250   \n",
       "2754  10991900       0          1.453336          1.212857         1.330002   \n",
       "33     3882000       1          0.026042          0.004464         0.072917   \n",
       "\n",
       "      Price_Range  \n",
       "2895     3.000000  \n",
       "4430     5.419983  \n",
       "3618    18.010010  \n",
       "763      9.312500  \n",
       "4392     8.239990  \n",
       "4657    27.700012  \n",
       "4008     6.570007  \n",
       "555      2.187500  \n",
       "2754     2.379997  \n",
       "33       0.083333  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(10, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Machine Learning Algorithms\n",
    "- After fitting them to the training data, we are going to evaluate their performance on the validation set by estimating the AUC metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the target column that we aim to predict\n",
    "y_col = \"Target\"\n",
    "# these are the input features for the models\n",
    "X_cols = [\n",
    "    \"Open\",\n",
    "    \"Close\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Volume\",\n",
    "    \"Adj Close\",\n",
    "    \"Today_Direction\",\n",
    "    \"Price_Range\",\n",
    "    \"Moving_Average_3\",\n",
    "    \"Moving_Average_7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[X_cols]\n",
    "y_train = df_train[y_col]\n",
    "\n",
    "X_val = df_val[X_cols]\n",
    "y_val = df_val[y_col]\n",
    "\n",
    "X_test = df_val[X_cols]\n",
    "y_test = df_val[y_col]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67       255\n",
      "           1       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.51       503\n",
      "   macro avg       0.25      0.50      0.34       503\n",
      "weighted avg       0.26      0.51      0.34       503\n",
      "\n",
      "SGDClassifier : 0.0\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.46      0.47       255\n",
      "           1       0.46      0.48      0.47       248\n",
      "\n",
      "    accuracy                           0.47       503\n",
      "   macro avg       0.47      0.47      0.47       503\n",
      "weighted avg       0.47      0.47      0.47       503\n",
      "\n",
      "KNeighborsClassifier : 0.4722222222222222\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       255\n",
      "           1       0.49      1.00      0.66       248\n",
      "\n",
      "    accuracy                           0.49       503\n",
      "   macro avg       0.25      0.50      0.33       503\n",
      "weighted avg       0.24      0.49      0.33       503\n",
      "\n",
      "LogisticRegression : 0.6604527296937417\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       255\n",
      "           1       0.49      1.00      0.66       248\n",
      "\n",
      "    accuracy                           0.49       503\n",
      "   macro avg       0.25      0.50      0.33       503\n",
      "weighted avg       0.24      0.49      0.33       503\n",
      "\n",
      "LogisticRegressionCV : 0.6604527296937417\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.77      0.62       255\n",
      "           1       0.51      0.24      0.33       248\n",
      "\n",
      "    accuracy                           0.51       503\n",
      "   macro avg       0.51      0.51      0.47       503\n",
      "weighted avg       0.51      0.51      0.47       503\n",
      "\n",
      "BaggingClassifier : 0.32786885245901637\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67       255\n",
      "           1       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.51       503\n",
      "   macro avg       0.25      0.50      0.34       503\n",
      "weighted avg       0.26      0.51      0.34       503\n",
      "\n",
      "GaussianNB : 0.0\n",
      "----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prashant.singh/anaconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.82      0.62       255\n",
      "           1       0.49      0.18      0.26       248\n",
      "\n",
      "    accuracy                           0.50       503\n",
      "   macro avg       0.50      0.50      0.44       503\n",
      "weighted avg       0.50      0.50      0.45       503\n",
      "\n",
      "RandomForestClassifier : 0.2647058823529412\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       255\n",
      "           1       0.54      0.08      0.15       248\n",
      "\n",
      "    accuracy                           0.51       503\n",
      "   macro avg       0.52      0.51      0.40       503\n",
      "weighted avg       0.52      0.51      0.41       503\n",
      "\n",
      "ExtraTreesClassifier : 0.1463414634146341\n",
      "----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.metrics import classification_report\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "# define the classifiers in an array\n",
    "classifiers = [\n",
    "    SGDClassifier(max_iter=1000, tol=1e-3, random_state=RANDOM_SEED),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(solver=\"lbfgs\", random_state=RANDOM_SEED),\n",
    "    LogisticRegressionCV(cv=3, random_state=RANDOM_SEED),\n",
    "    BaggingClassifier(random_state=RANDOM_SEED),\n",
    "    GaussianNB(),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    ExtraTreesClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "]\n",
    "\n",
    "# iterate over the array of classifiers and print their evaluation\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X=X_train, y=y_train)\n",
    "    y_pred = classifier.predict(X=X_test)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "    print(classifier.__class__.__name__, \":\", f1)\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Algorithm - Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# set seed for reproducibility of results\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Tensorflow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Normalization(axis=-1),\n",
    "    tf.keras.layers.Dense(10, input_shape=[X_train.shape[1],], activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "    tf.keras.layers.Dropout(0.2, seed=RANDOM_SEED),\n",
    "    tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\", kernel_initializer='random_normal', bias_initializer='zeros')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this configures the model's loss function, weight optimizer, and metrics to keep track of\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch, learning_rate):\n",
    "    \"\"\"Learning rate decay callback.\"\"\"\n",
    "    if epoch < 5:\n",
    "        return learning_rate\n",
    "    else:\n",
    "        return learning_rate * tf.math.exp(-0.01)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 13:37:53.259850: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 1s 1ms/step - loss: 395.1616 - auc: 0.5018 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 670us/step - loss: 8.0725 - auc: 0.4998 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 742us/step - loss: 2.9414 - auc: 0.5004 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 723us/step - loss: 1.5638 - auc: 0.5057 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 749us/step - loss: 1.7217 - auc: 0.4983 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 660us/step - loss: 2.0560 - auc: 0.4924 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.9005e-04\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 644us/step - loss: 1.0140 - auc: 0.4929 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.8020e-04\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 627us/step - loss: 1.3563 - auc: 0.4998 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.7045e-04\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 634us/step - loss: 0.7251 - auc: 0.4910 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.6079e-04\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 617us/step - loss: 0.8845 - auc: 0.5004 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.5123e-04\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 640us/step - loss: 0.7485 - auc: 0.4919 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.4176e-04\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 634us/step - loss: 0.7249 - auc: 0.5008 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.3239e-04\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 616us/step - loss: 0.7327 - auc: 0.4974 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.2312e-04\n",
      "Epoch 14/50\n",
      " 99/150 [==================>...........] - ETA: 0s - loss: 0.7202 - auc: 0.4991Restoring model weights from the end of the best epoch: 4.\n",
      "150/150 [==============================] - 0s 666us/step - loss: 0.7581 - auc: 0.4992 - val_loss: 0.6931 - val_auc: 0.5000 - lr: 9.1393e-04\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_callback, learning_rate_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Algorithm - Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 4781)]            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                95640     \n",
      "                                                                 \n",
      " normalization_3 (Normalizat  (None, 20)               41        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,702\n",
      "Trainable params: 95,661\n",
      "Non-trainable params: 41\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras import backend as K\n",
    "# set random for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = keras.Input(shape=(X_train.shape[0],))\n",
    "x = layers.Dense(20,activation='relu',kernel_initializer='GlorotNormal')(inputs)\n",
    "x1=layers.Normalization(axis=-1)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x1)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 10), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, 10).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 10), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, 10).\n",
      " 79/150 [==============>...............] - ETA: 0s - loss: 7.7552 - auc: 0.5000 WARNING:tensorflow:Model was constructed with shape (None, None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 10), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, 10).\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 2/50000\n",
      "150/150 [==============================] - 0s 612us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 3/50000\n",
      "150/150 [==============================] - 0s 605us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 4/50000\n",
      "150/150 [==============================] - 0s 605us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 5/50000\n",
      "150/150 [==============================] - 0s 605us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 0.0010\n",
      "Epoch 6/50000\n",
      "150/150 [==============================] - 0s 673us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.9005e-04\n",
      "Epoch 7/50000\n",
      "150/150 [==============================] - 0s 718us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.8020e-04\n",
      "Epoch 8/50000\n",
      "150/150 [==============================] - 0s 713us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.7045e-04\n",
      "Epoch 9/50000\n",
      "150/150 [==============================] - 0s 702us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.6079e-04\n",
      "Epoch 10/50000\n",
      "150/150 [==============================] - 0s 701us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.5123e-04\n",
      "Epoch 11/50000\n",
      "104/150 [===================>..........] - ETA: 0s - loss: 7.6012 - auc: 0.5000Restoring model weights from the end of the best epoch: 1.\n",
      "150/150 [==============================] - 0s 629us/step - loss: 7.7173 - auc: 0.5000 - val_loss: 7.6051 - val_auc: 0.5000 - lr: 9.4176e-04\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras import backend as K\n",
    "# set random for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = keras.Input(shape=(None,X_train.shape[1]))\n",
    "x = layers.Dense(20,activation='relu',kernel_initializer='GlorotNormal')(inputs)\n",
    "x1=layers.Normalization(axis=-1)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x1)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['AUC']\n",
    ")\n",
    "def learning_rate_scheduler(epoch, learning_rate):\n",
    "    \"\"\"Learning rate decay callback.\"\"\"\n",
    "    if epoch < 5:\n",
    "        return learning_rate\n",
    "    else:\n",
    "        return learning_rate * tf.math.exp(-0.01)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50000,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_callback, learning_rate_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6xUlEQVR4nO3de3wU9b3/8fcm2SxJDHcCSQwGKchFQATkBHpAhSQCorQUD00sQY5aYZFATj0RKgJeAKXlcCoWiweiFpAqBUFBIVHQegGiHhQKJlIxoUigGEO4SLLJzu8PfmzdkwSysDubZF7Px2MfZWa++93PfDDk3ZnZGZthGIYAAAAsJCTYBQAAAJiNAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACwnLNgFNERut1vffPONoqOjZbPZgl0OAACoB8MwdOrUKcXFxSkk5OLHeAhAtfjmm2+UkJAQ7DIAAMBlOHz4sK6++uqLjiEA1SI6OlrS+QY2b97cr3O7XC5t27ZNKSkpstvtfp0b/0SfzUGfzUGfzUGfzROoXpeXlyshIcHze/xiCEC1uHDaq3nz5gEJQJGRkWrevDk/YAFEn81Bn81Bn81Bn80T6F7X5/IVLoIGAACWQwACAACWE9QAlJiYKJvNVuPldDprHX/zzTfXOn7UqFGSzh9Sy87OVq9evRQVFaW4uDhNmDBB33zzjZm7BQAAGrigXgOUn5+v6upqz/K+ffuUnJyscePG1Tp+/fr1qqys9Cx/++236tOnj2f82bNn9emnn2r27Nnq06ePvvvuO2VmZuqOO+7Qxx9/HNidAQAAjUZQA1C7du28lhcuXKjOnTtr6NChtY5v3bq11/LatWsVGRnpCUAtWrRQbm6u15ilS5fqpptuUnFxsTp27OjH6gEAQGPVYL4FVllZqVWrVikrK6veNx9csWKFxo8fr6ioqDrHnDx5UjabTS1btqxzTEVFhSoqKjzL5eXlks6fUnO5XPXbgXq6MJ+/54U3+mwO+mwO+mwO+myeQPXal/lshmEYfv30y/TKK68oLS1NxcXFiouLu+T43bt3a+DAgdq1a5duuummWsecO3dOgwcPVrdu3bR69eo655o7d67mzZtXY/2aNWsUGRlZ/50AAABBc/bsWaWlpenkyZOXvI1NgwlAqampCg8P1+uvv16v8b/85S/10Ucf6fPPP691u8vl0tixY/X3v/9dO3bsuGgjajsClJCQoBMnTgTkPkC5ublKTk7mPhMBRJ/NQZ/NQZ/NQZ/NE6hel5eXq23btvUKQA3iFFhRUZHy8vK0fv36eo0/c+aM1q5dq8cee6zW7S6XS3fddZeKior0zjvvXLIJDodDDoejxnq73R6wH4JAzo1/os/moM/moM/moM/m8XevfZmrQQSgnJwcxcTEeL7OfimvvvqqKioqdPfdd9fYdiH8fPnll9q+fbvatGnj73IBAEAjF/QbIbrdbuXk5CgjI0NhYd55bMKECZo5c2aN96xYsUJjxoypEW5cLpd+9rOf6eOPP9bq1atVXV2tkpISlZSUeH19HgAAWFvQjwDl5eWpuLhYkyZNqrGtuLi4xuPsCwoK9P7772vbtm01xh85ckSbNm2SJN1www1e27Zv366bb77Zb3UDAIDGK+gBKCUlRXVdh71jx44a66677ro6xycmJta5rSE4W1mlf5z8XqUV0jdl3yvMXhXskpqsKpeLPpvgQp+PnjynsDBr9PlK/oW53H+fqqqqVFohHSn7XmFh/v+Kdn1vPXJZcwdsZv+rqqrSdxb77/lSAvUbtcrl0ukg322gwXwLrCEpLy9XixYt6nUVuS82ffaNpr38v36bDwCAxurGNm79afptfv8WWH1/fwf9CJCVhNpscoSFyF1drZDQ0GCX06QZkgz6bIrqxthnQwE7NBGoIx6N8d+Nxvj/rqurqxUSEiJbozp2pcZ1qO3/Cw1xB/XzCUAmGtU7Vind22rLli0aOTKVr1kGkMvlos8moM/moM/moM/mudDrYAr6t8AAAADMRgACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWE9QAlJiYKJvNVuPldDprHX/zzTfXOn7UqFGeMYZh6NFHH1VsbKwiIiI0fPhwffnll2btEgAAaASCGoDy8/N19OhRzys3N1eSNG7cuFrHr1+/3mv8vn37FBoa6jX+6aef1u9+9zs999xz2rVrl6KiopSamqpz586Zsk8AAKDhCwvmh7dr185reeHChercubOGDh1a6/jWrVt7La9du1aRkZGeAGQYhpYsWaJHHnlEd955pyTppZdeUvv27fXaa69p/PjxAdgLAADQ2AQ1AP1QZWWlVq1apaysLNlstnq9Z8WKFRo/fryioqIkSYcOHVJJSYmGDx/uGdOiRQsNHDhQH330UZ0BqKKiQhUVFZ7l8vJySZLL5ZLL5brcXarVhfn8PS+80Wdz0Gdz0Gdz0GfzBKrXvszXYALQa6+9prKyMk2cOLFe43fv3q19+/ZpxYoVnnUlJSWSpPbt23uNbd++vWdbbRYsWKB58+bVWL9t2zZFRkbWqx5fXTjdh8Ciz+agz+agz+agz+bxd6/Pnj1b77ENJgCtWLFCI0aMUFxcXL3H9+rVSzfddNMVf/bMmTOVlZXlWS4vL1dCQoJSUlLUvHnzK57/h1wul3Jzc5WcnCy73e7XufFP9Nkc9Nkc9Nkc9Nk8ger1hTM49dEgAlBRUZHy8vK0fv36eo0/c+aM1q5dq8cee8xrfYcOHSRJx44dU2xsrGf9sWPHdMMNN9Q5n8PhkMPhqLHebrcH7IcgkHPjn+izOeizOeizOeizefzda1/mahD3AcrJyVFMTIzX19kv5tVXX1VFRYXuvvtur/WdOnVShw4d9Pbbb3vWlZeXa9euXUpKSvJrzQAAoPEKegByu93KyclRRkaGwsK8D0hNmDBBM2fOrPGeFStWaMyYMWrTpo3XepvNpunTp+uJJ57Qpk2btHfvXk2YMEFxcXEaM2ZMIHcDAAA0IkE/BZaXl6fi4mJNmjSpxrbi4mKFhHhntIKCAr3//vvatm1brfP953/+p86cOaP7779fZWVl+vGPf6y33npLzZo1C0j9AACg8Ql6AEpJSZFhGLVu27FjR4111113XZ3jpfNHgR577LEa1wcBAABcEPRTYAAAAGYjAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMsJagBKTEyUzWar8XI6nXW+p6ysTE6nU7GxsXI4HOratau2bNni2V5dXa3Zs2erU6dOioiIUOfOnfX444/LMAwzdgkAADQCYcH88Pz8fFVXV3uW9+3bp+TkZI0bN67W8ZWVlUpOTlZMTIzWrVun+Ph4FRUVqWXLlp4xTz31lJYtW6YXX3xRPXv21Mcff6x77rlHLVq00LRp0wK9SwAAoBEIagBq166d1/LChQvVuXNnDR06tNbxK1euVGlpqT788EPZ7XZJ548i/dCHH36oO++8U6NGjfJsf/nll7V7927/7wAAAGiUghqAfqiyslKrVq1SVlaWbDZbrWM2bdqkpKQkOZ1Obdy4Ue3atVNaWpqys7MVGhoqSRo0aJCWL1+uwsJCde3aVZ999pnef/99LV68uM7PrqioUEVFhWe5vLxckuRyueRyufy4l/LM5+954Y0+m4M+m4M+m4M+mydQvfZlPpvRQC6OeeWVV5SWlqbi4mLFxcXVOqZbt276+uuvlZ6erilTpujgwYOaMmWKpk2bpjlz5kiS3G63Zs2apaefflqhoaGqrq7Wk08+qZkzZ9b52XPnztW8efNqrF+zZo0iIyP9s4MAACCgzp49q7S0NJ08eVLNmze/6NgGE4BSU1MVHh6u119/vc4xXbt21blz53To0CHPEZ/Fixdr0aJFOnr0qCRp7dq1euihh7Ro0SL17NlTe/bs0fTp07V48WJlZGTUOm9tR4ASEhJ04sSJSzbQVy6XS7m5uUpOTvacxoP/0Wdz0Gdz0Gdz0GfzBKrX5eXlatu2bb0CUIM4BVZUVKS8vDytX7/+ouNiY2Nlt9s94UeSunfvrpKSElVWVio8PFwPPfSQHn74YY0fP16S1KtXLxUVFWnBggV1BiCHwyGHw1Fjvd1uD9gPQSDnxj/RZ3PQZ3PQZ3PQZ/P4u9e+zNUg7gOUk5OjmJgYz4XLdRk8eLAOHjwot9vtWVdYWKjY2FiFh4dLOn/4KyTEe7dCQ0O93gMAAKwt6AHI7XYrJydHGRkZCgvzPiA1YcIEr2t3Jk+erNLSUmVmZqqwsFCbN2/W/Pnzve4bNHr0aD355JPavHmzvv76a23YsEGLFy/WT37yE9P2CQAANGxBPwWWl5en4uJiTZo0qca24uJir6M5CQkJ2rp1q2bMmKHevXsrPj5emZmZys7O9ox55plnNHv2bE2ZMkXHjx9XXFycfvnLX+rRRx81ZX8AAEDDF/QAlJKSUuddmnfs2FFjXVJSknbu3FnnfNHR0VqyZImWLFnipwoBAEBTE/RTYAAAAGYjAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMup152gy8vLfZ74Uo+hBwAACJZ6BaCWLVvKZrPVe1KbzabCwkJde+21l10YAABAoNT7WWDr1q1T69atLznOMAyNHDnyiooCAAAIpHoFoGuuuUZDhgxRmzZt6jXptddeK7vdfkWFAQAABEq9AtChQ4d8mnTfvn2XVQwAAIAZruhbYOfOnfNXHQAAAKbxOQC53W49/vjjio+P11VXXaWvvvpKkjR79mytWLHC7wUCAAD4m88B6IknntALL7ygp59+WuHh4Z71119/vf7nf/7Hr8UBAAAEgs8B6KWXXtLy5cuVnp6u0NBQz/o+ffroiy++8GtxAAAAgeBzADpy5Ih+9KMf1Vjvdrvlcrn8UhQAAEAg+RyAevToob/85S811q9bt059+/b1S1EAAACBVO8bIV7w6KOPKiMjQ0eOHJHb7db69etVUFCgl156SW+88UYgagQAAPArn48A3XnnnXr99deVl5enqKgoPfroozpw4IBef/11JScnB6JGAAAAv/L5CJAk/eu//qtyc3P9XQsAAIApfD4ClJ+fr127dtVYv2vXLn388cd+KQoAACCQfA5ATqdThw8frrH+yJEjcjqdfikKAAAgkHw+BbZ//37deOONNdb37dtX+/fv90tRAAA0BNXV1dziJQBcLpfCwsJ07tw5VVdX1/t9drvd6x6EV8LnAORwOHTs2DFde+21XuuPHj2qsLDLuqQIAIAGxTAMlZSUqKysLNilNEmGYahDhw46fPiwbDabT+9t2bKlOnTo4PP7/i+fE0tKSopmzpypjRs3qkWLFpKksrIyzZo1i2+BAQCahAvhJyYmRpGRkVf8yxbe3G63Tp8+rauuukohIfW7GscwDJ09e1bHjx+XJMXGxl5RDT4HoN/85jcaMmSIrrnmGs+ND/fs2aP27dvrj3/84xUVAwBAsFVXV3vCT5s2bYJdTpPkdrtVWVmpZs2a1TsASVJERIQk6fjx44qJibmi02E+B6D4+Hh9/vnnWr16tT777DNFRETonnvu0c9//nPZ7fbLLgQAgIagqqpKkhQZGRnkSlCbC38vLpfL3AAkSVFRUbr//vsv+0MBAGioDMOQJE57NVD++nupVwDatGmTRowYIbvdrk2bNl107B133OGXwgAAAAKlXgFozJgxKikpUUxMjMaMGVPnOJvN5tPX2QAAgP/cfPPNuuGGG7RkyZJgl9Lg1SsAud3uWv8MAADQGPl0J2iXy6Vhw4bpyy+/DFQ9AAAAAedTALLb7fr8888DVQsAAPCT7777ThMmTFCrVq0UGRmpESNGeB3AKCoq0ujRo9WqVStFRUWpZ8+e2rJli+e96enpateunSIiItSlSxfl5OQEa1cCwudvgd19991asWKFFi5cGIh6AABoUAzD0Peu4FzfGmEPvexvPU2cOFFffvmlNm3apObNmys7O1sjR47U/v37Zbfb5XQ6VVlZqffee09RUVHav3+/rrrqKknS7NmztX//fr355ptq27atDh48qO+//96fuxZ0PgegqqoqrVy5Unl5eerXr5+ioqK8ti9evNhvxQEAEGzfu6rV49GtQfns/Y+lKjLc9zvWXAg+H3zwgQYNGiRJWr16tRISEvTaa69p3LhxKi4u1tixY9WrVy9J8nrEVXFxsfr27av+/ftLkhITE698ZxoYn7u6b98+z8NQCwsLvbZxzwQAAILvwIEDCgsL08CBAz3r2rRpo+uuu04HDhyQJE2bNk2TJ0/Wtm3bNHz4cI0dO1a9e/eWJE2ePFljx47Vp59+qpSUFI0ZM8YTpJoKnwPQ9u3bA1EHAAANUoQ9VPsfSw3aZwfKvffeq9TUVG3evFnbtm3TggUL9Nvf/lYPPvigRowYoaKiIm3ZskW5ubkaNmyYnE6nfvOb3wSsHrP5dBH0n/70J6Wnp2vcuHF67rnnAlUTAAANhs1mU2R4WFBel3tmpXv37qqqqtKuXbs867799lsVFBSoR48ennUJCQl64IEHtH79ev3Hf/yHnn/+ec+2du3aKSMjQ6tWrdKSJUu0fPnyy29iA1TvI0DLli2T0+lUly5dFBERofXr1+tvf/ubFi1aFMj6AACAj7p06aI777xT9913n/7whz8oOjpaDz/8sOLj43XnnXdKkqZPn64RI0aoa9eu+u6777R9+3Z1795dkvToo4+qX79+6tmzpyoqKvTGG294tjUV9T4CtHTpUs2ZM0cFBQXas2ePXnzxRf3+978PZG0AAOAy5eTkqF+/frr99tuVlJQkwzC0ZcsWz4PLq6ur5XQ61b17d912223q2rWr5/d6eHi4Zs6cqd69e2vIkCEKDQ3V2rVrg7k7flfvI0BfffWVMjIyPMtpaWn693//dx09elSxsbEBKQ4AANTfjh07PH9u1aqVXnrppTrHPvPMM3Vue+SRR/TII4/4s7QGp95HgCoqKry+8h4SEqLw8PAmd18AAADQ9Pn0LbDZs2crMjLSs1xZWaknn3xSLVq08KzjPkAAAKChq3cAGjJkiAoKCrzWDRo0SF999ZVnmfsAAQCAxqDeAeiH5xUBAAAaM5/uAwQAANAU1CsAZWVl6cyZM/WedObMmSotLb3kuMTERNlsthovp9NZ53vKysrkdDoVGxsrh8Ohrl27ep5ee8GRI0d09913q02bNoqIiFCvXr308ccf17t+AADQtNUrAP33f/+3zp49W+9Jn332WZWVlV1yXH5+vo4ePep55ebmSpLGjRtX6/jKykolJyfr66+/1rp161RQUKDnn39e8fHxnjHfffedBg8eLLvdrjfffFP79+/Xb3/7W7Vq1are9QMAgKatXtcAGYahrl271vsi5/oeLWrXrp3X8sKFC9W5c2cNHTq01vErV65UaWmpPvzwQ8+NnP7vE2qfeuopJSQkKCcnx7OuU6dO9aoHAABYQ70C0A/DRH21b9/ep/GVlZVatWqVsrKy6gxamzZtUlJSkpxOpzZu3Kh27dopLS1N2dnZCg0N9YxJTU3VuHHj9O677yo+Pl5TpkzRfffdV+dnV1RUqKKiwrNcXl4uSXK5XHK5XD7tx6VcmM/f88IbfTYHfTYHfTbHhf5WVVXJMAy53W653e4gV9U0GYbh+V9fe+x2u2UYhlwul+d3/wW+/IzYjAtVBNkrr7yitLQ0FRcXKy4urtYx3bp109dff6309HRNmTJFBw8e1JQpUzRt2jTNmTNHktSsWTNJ569bGjdunPLz85WZmannnnvO607WPzR37lzNmzevxvo1a9Z43fcIAND0hYWFqUOHDkpISFB4eHiwyzFV7969NXnyZE2ePPmSY1u1aqVVq1Zp1KhRJlT2T5WVlTp8+LBKSkpUVVXlte3s2bNKS0vTyZMn1bx584vO02ACUGpqqsLDw/X666/XOaZr1646d+6cDh065El9ixcv1qJFi3T06FFJ559f0r9/f3344Yee902bNk35+fn66KOPap23tiNACQkJOnHixCUb6CuXy6Xc3FwlJyd7TuPB/+izOeizOeizOS70eciQITp69KgSExM9/6faKq699lplZmYqMzPzkmNDQ0P15z//WWPGjPH5cwzD0KlTpxQdHe3zPQTPnTunr7/+WgkJCTX+fsrLy9W2bdt6BSCf7gQdKEVFRcrLy9P69esvOi42NlZ2u93rkFf37t1VUlKiyspKhYeHKzY2Vj169PB6X/fu3fXnP/+5znkdDoccDkeN9Xa7PWD/2ARybvwTfTYHfTYHfTZHWFiYbDabQkJCFBJivbvFXNj3+rjcHl047eXLZ/3wM202W60/D778fDSIv9mcnBzFxMRc8jDa4MGDdfDgQa/zhYWFhYqNjfUcphw8eHCNO1YXFhbqmmuu8X/hAICmzzCkyjPBeflwkmb58uWKi4urcU3NnXfeqUmTJulvf/ub7rzzTrVv315XXXWVBgwYoLy8PL+1ae/evbr11lsVERGhNm3a6P7779fp06c923fs2KGbbrpJUVFRat26tVJTU1VUVCRJ+uyzz3TLLbcoOjpazZs3V79+/QJ++5qgHwFyu93KyclRRkaGwsK8y5kwYYLi4+O1YMECSdLkyZO1dOlSZWZm6sEHH9SXX36p+fPna9q0aZ73zJgxQ4MGDdL8+fN11113affu3Vq+fLmWL19u6n4BAJoI11lpfu3XpgbcrG+k8KhLj9P5W8g8+OCD2r59u4YNGyZJKi0t1VtvvaUtW7bo9OnTGjlypJ588kk5HA699NJLGj16tAoKCtSxY8crKvPMmTNKTU1VUlKS8vPzdfz4cd17772aOnWqXnjhBVVVVWnMmDG677779PLLL+vcuXN67733PKe/0tPT1bdvXy1btkyhoaHas2dPwI92+hSAXC6XIiIitGfPHl1//fV+KSAvL0/FxcWaNGlSjW3FxcVeh8YSEhK0detWzZgxQ71791Z8fLwyMzOVnZ3tGTNgwABt2LBBM2fO1GOPPaZOnTppyZIlSk9P90u9AAA0RK1atdKIESO0Zs0aTwBat26d2rZtq1tuuUUhISHq06ePZ/zjjz+uDRs2aNOmTZo6deoVffaaNWt07tw5vfTSS4qKOh/Yli5dqtGjR+upp56S3W7XyZMndfvtt6tz585yu92Kj4/3XKdTXFyshx56SN26dZMkdenS5YrqqQ+fApDdblfHjh1VXV3ttwJSUlJU13XYtT1/LCkpSTt37rzonLfffrtuv/12f5QHALA6e+T5IzHB+mwfpKen67777tPvf/97ORwOrV69WuPHj1dISIhOnz6tuXPnavPmzTp69Kiqqqr0/fffq7i4+IrLPHDggPr06eMJP9L5S1LcbrcKCgo0ZMgQTZw4UampqUpOTtawYcN02223eQJQVlaW7r33Xv3xj3/U8OHDNW7cOHXu3PmK67oYn68B+vWvf61Zs2bV61EXAAA0ejbb+dNQwXj5+A2p0aNHyzAMbd68WYcPH9Zf/vIXzxmQX/3qV9qwYYPmz5+vv/zlL9qzZ4969eqlysrKQHSthpycHH300UcaNGiQXnnlFQ0YMMBzQGPu3Ln661//qlGjRumdd95Rjx49tGHDhoDW4/M1QEuXLtXBgwcVFxena665xivtSdKnn37qt+IAAED9NWvWTD/96U+1evVqHTx4UNddd51uvPFGSdIHH3ygiRMn6ic/+Ykk6fTp0/r666/98rndu3fXCy+8oDNnznhywQcffKCQkBBdd911nnF9+/ZV3759lZ2drX/5l3/Ryy+/rEGDBkk6f6ubrl27asaMGfr5z3+unJwcT62B4HMAupzv+wMAAHOkp6fr9ttv11//+lfdfffdnvVdunTR+vXrNXr0aNlsNs2ePdtvd7pOT0/XnDlzlJGRoblz5+of//iHHnzwQf3iF79Q+/btdejQIS1fvlx33HGH4uLidODAAf3tb39TRkaGvv/+ez300EP62c9+pk6dOunvf/+78vPzNXbsWL/UVhefA9CFOy4DAICG59Zbb1Xr1q1VUFCgtLQ0z/rFixdr0qRJGjRokNq2bavs7GzPo5+uVGRkpLZu3arMzEwNGDBAkZGRGjt2rBYvXuzZ/sUXX+jFF1/Ut99+q9jYWN1777365S9/KbfbrW+//VYTJkzQsWPH1LZtW/30pz+t9QkN/nTZX4P/5JNPdODAAUlSz5491bdvX78VBQAALk9ISIi++abmRduJiYl65513vNY5nU6vZV9Oif3fLzD16tWrxvwXtG/f3uuaHrfbrfLycoWEhCgsLEwvv/xyvT/XX3wOQMePH9f48eO1Y8cOtWzZUpJUVlamW265RWvXrq3xhHcAAICGxudvgT344IM6deqU/vrXv6q0tFSlpaXat2+fysvLvW5ICAAAGqfVq1frqquuqvXVs2fPYJfnFz4fAXrrrbeUl5en7t27e9b16NFDzz77rFJSUvxaHAAAMN8dd9yhgQMH1rqtqTyPzucA5Ha7a915u93ut6vJAQBA8ERHRys6OjrYZQSUz6fAbr31VmVmZnpdYHXkyBHNmDHDc+ttAAAaqwvPp6rrKQUILn/9vfgcgJYuXary8nIlJiaqc+fO6ty5szp16qTy8nI988wzfikKAIBgufBg7rNnzwa5EtTmwt/LlZ6K8/kUWEJCgj799FPl5eXpiy++kHT+DpDDhw+/okIAAGgIQkND1bJlSx0/flzS+XvY2Hx8JAUuzu12q7KyUufOnfN66PnFGIahs2fP6vjx42rZsqVCQ0OvqIbLfhp8cnKykpOTr+jDAQBoiDp06CBJnhAE/zIMQ99//70iIiJ8DpctW7b0/P1ciaA/DR4AgIbGZrMpNjZWMTExcrlcwS6nyXG5XHrvvfc0ZMgQn05l2e32Kz7yc4HPp8AuPA3+j3/8o1q3bu2XIgAAaIhCQ0P99gsX/xQaGqqqqio1a9YsaF+r52nwAADAcngaPAAAsByfAlBVVZVsNpsmTZqkq6++OlA1AQAABJRP9wEKCwvTokWLVFVVFah6AAAAAu6y7gT97rvvBqIWAAAAU/h8DdCIESP08MMPa+/everXr1+Ni6DvuOMOvxUHAAAQCD4HoClTpkiSFi9eXGObzWbjHkEAAKDBu6ynwQMAADRmPl8DBAAA0NjVOwCNHDlSJ0+e9CwvXLhQZWVlnuVvv/1WPXr08GtxAAAAgVDvALR161ZVVFR4lufPn6/S0lLPclVVlQoKCvxbHQAAQADUOwAZhnHRZQAAgMaCa4AAAIDl1DsA2Ww22Wy2GusAAAAam3p/Dd4wDE2cOFEOh0OSdO7cOT3wwAOeGyH+8PogAACAhqzeASgjI8Nr+e67764xZsKECVdeEQAAQIDVOwDl5OQEsg4AAADTcBE0AACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwnKAGoMTERNlsthovp9NZ53vKysrkdDoVGxsrh8Ohrl27asuWLbWOXbhwoWw2m6ZPnx6gPQAAAI1RWDA/PD8/X9XV1Z7lffv2KTk5WePGjat1fGVlpZKTkxUTE6N169YpPj5eRUVFatmyZa1z/+EPf1Dv3r0DVT4AAGikghqA2rVr57W8cOFCde7cWUOHDq11/MqVK1VaWqoPP/xQdrtd0vmjSP/X6dOnlZ6erueff15PPPGE3+sGAACNW1AD0A9VVlZq1apVysrKks1mq3XMpk2blJSUJKfTqY0bN6pdu3ZKS0tTdna2QkNDPeOcTqdGjRql4cOH1ysAVVRUqKKiwrNcXl4uSXK5XHK5XFe4Z94uzOfveeGNPpuDPpuDPpuDPpsnUL32Zb4GE4Bee+01lZWVaeLEiXWO+eqrr/TOO+8oPT1dW7Zs0cGDBzVlyhS5XC7NmTNHkrR27Vp9+umnys/Pr/dnL1iwQPPmzauxftu2bYqMjPR5X+ojNzc3IPPCG302B302B302B302j797ffbs2XqPtRmGYfj10y9TamqqwsPD9frrr9c5pmvXrjp37pwOHTrkOeKzePFiLVq0SEePHtXhw4fVv39/5ebmeq79ufnmm3XDDTdoyZIldc5b2xGghIQEnThxQs2bN/fPDv5/LpdLubm5Sk5O9pzGg//RZ3PQZ3PQZ3PQZ/MEqtfl5eVq27atTp48ecnf3w3iCFBRUZHy8vK0fv36i46LjY2V3W73Ot3VvXt3lZSUqLKyUp988omOHz+uG2+80bO9urpa7733npYuXaqKigqv917gcDjkcDhqrLfb7QH7IQjk3Pgn+mwO+mwO+mwO+mwef/fal7kaRADKyclRTEyMRo0addFxgwcP1po1a+R2uxUScv4b/IWFhYqNjVV4eLiGDRumvXv3er3nnnvuUbdu3WpcJwQAAKwr6DdCdLvdysnJUUZGhsLCvPPYhAkTNHPmTM/y5MmTVVpaqszMTBUWFmrz5s2aP3++575B0dHRuv76671eUVFRatOmja6//npT9wsAADRcQT8ClJeXp+LiYk2aNKnGtuLiYs+RHklKSEjQ1q1bNWPGDPXu3Vvx8fHKzMxUdna2mSUDAIBGLugBKCUlRXVdh71jx44a65KSkrRz5856z1/bHAAAwNqCfgoMAADAbAQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOUENQImJibLZbDVeTqezzveUlZXJ6XQqNjZWDodDXbt21ZYtWzzbFyxYoAEDBig6OloxMTEaM2aMCgoKzNgdAADQSIQF88Pz8/NVXV3tWd63b5+Sk5M1bty4WsdXVlYqOTlZMTExWrduneLj41VUVKSWLVt6xrz77rtyOp0aMGCAqqqqNGvWLKWkpGj//v2KiooK9C4BAIBGIKgBqF27dl7LCxcuVOfOnTV06NBax69cuVKlpaX68MMPZbfbJZ0/ivRDb731ltfyCy+8oJiYGH3yyScaMmRIrfNWVFSooqLCs1xeXi5JcrlccrlcPu3TpVyYz9/zwht9Ngd9Ngd9Ngd9Nk+geu3LfDbDMAy/fvplqqysVFxcnLKysjRr1qxax4wcOVKtW7dWZGSkNm7cqHbt2iktLU3Z2dkKDQ2t9T0HDx5Uly5dtHfvXl1//fW1jpk7d67mzZtXY/2aNWsUGRl5+TsFAABMc/bsWaWlpenkyZNq3rz5Rcc2mAD0yiuvKC0tTcXFxYqLi6t1TLdu3fT1118rPT1dU6ZM0cGDBzVlyhRNmzZNc+bMqTHe7XbrjjvuUFlZmd5///06P7u2I0AJCQk6ceLEJRvoK5fLpdzcXCUnJ3uOYsH/6LM56LM56LM56LN5AtXr8vJytW3btl4BKKinwH5oxYoVGjFiRJ3hRzofaGJiYrR8+XKFhoaqX79+OnLkiBYtWlRrAHI6ndq3b99Fw48kORwOORyOGuvtdnvAfggCOTf+iT6bgz6bgz6bgz6bx9+99mWuBhGAioqKlJeXp/Xr1190XGxsrOx2u9fpru7du6ukpESVlZUKDw/3rJ86dareeOMNvffee7r66qsDVjsAAGh8GsR9gHJychQTE6NRo0ZddNzgwYN18OBBud1uz7rCwkLFxsZ6wo9hGJo6dao2bNigd955R506dQpo7QAAoPEJegByu93KyclRRkaGwsK8D0hNmDBBM2fO9CxPnjxZpaWlyszMVGFhoTZv3qz58+d73TfI6XRq1apVWrNmjaKjo1VSUqKSkhJ9//33pu0TAABo2IJ+CiwvL0/FxcWaNGlSjW3FxcUKCflnRktISNDWrVs1Y8YM9e7dW/Hx8crMzFR2drZnzLJlyyRJN998s9dcOTk5mjhxYkD2AQAANC5BD0ApKSmq64toO3bsqLEuKSlJO3furHO+BvKlNgAA0IAF/RQYAACA2QhAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcsKCXYClGIZUeUah1RVS5RnJsAe7oqbL5aLPZqDP5qDP5qDP5rnQa8MIWgk2wwjipzdQ5eXlatGihU6ePKnmzZv7b+LKM9L8OP/NBwBAI+Z6qEj2qJZ+m8+X39+cAgMAAJbDKTAz2SPleqhIW7duU2pqiux2DrEGisvlos8moM/moM/moM/m8fTaHhm0GghAZrLZpPAoVYc6pPAoiR+wwLG56LMZ6LM56LM56LN5LvTaZgtaCZwCAwAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlhPUAJSYmCibzVbj5XQ663xPWVmZnE6nYmNj5XA41LVrV23ZssVrzLPPPqvExEQ1a9ZMAwcO1O7duwO9KwAAoBEJ6qMw8vPzVV1d7Vnet2+fkpOTNW7cuFrHV1ZWKjk5WTExMVq3bp3i4+NVVFSkli1besb86U9/UlZWlp577jkNHDhQS5YsUWpqqgoKChQTExPoXQIAAI1AUANQu3btvJYXLlyozp07a+jQobWOX7lypUpLS/Xhhx96HlSXmJjoNWbx4sW67777dM8990iSnnvuOW3evFkrV67Uww8/XOu8FRUVqqio8CyXl5dLOv+wNpfLdVn7VpcL8/l7Xnijz+agz+agz+agz+YJVK99mc9mGIbh10+/TJWVlYqLi1NWVpZmzZpV65iRI0eqdevWioyM1MaNG9WuXTulpaUpOztboaGhqqysVGRkpNatW6cxY8Z43peRkaGysjJt3Lix1nnnzp2refPm1Vi/Zs0aRUYG70m1AACg/s6ePau0tDSdPHlSzZs3v+jYBvM0+Ndee01lZWWaOHFinWO++uorvfPOO0pPT9eWLVt08OBBTZkyRS6XS3PmzNGJEydUXV2t9u3be72vffv2+uKLL+qcd+bMmcrKyvIsnzx5Uh07dlRSUpKio6OveN9+yOVyafv27brllls8R7Hgf/TZHPTZHPTZHPTZPIHq9alTpyRJ9Tm202AC0IoVKzRixAjFxcXVOcbtdismJkbLly9XaGio+vXrpyNHjmjRokWaM2fOZX+2w+GQw+HwLF84BdapU6fLnhMAAATHqVOn1KJFi4uOaRABqKioSHl5eVq/fv1Fx8XGxsputys0NNSzrnv37iopKVFlZaXatm2r0NBQHTt2zOt9x44dU4cOHepdT1xcnA4fPqzo6GjZbDbfduYSysvLlZCQoMOHD1/y8BwuH302B302B302B302T6B6bRiGTp06ddGDKRc0iACUk5OjmJgYjRo16qLjBg8erDVr1sjtdisk5Pw3+AsLCxUbG6vw8HBJUr9+/fT22297rgFyu916++23NXXq1HrXExISoquvvvrydqaemjdvzg+YCeizOeizOeizOeizeQLR60sd+bkg6DdCdLvdysnJUUZGhsLCvPPYhAkTNHPmTM/y5MmTVVpaqszMTBUWFmrz5s2aP3++132DsrKy9Pzzz+vFF1/UgQMHNHnyZJ05c8bzrTAAAICgHwHKy8tTcXGxJk2aVGNbcXGx50iPJCUkJGjr1q2aMWOGevfurfj4eGVmZio7O9sz5t/+7d/0j3/8Q48++qhKSkp0ww036K233qpxYTQAALCuoAeglJSUOq/W3rFjR411SUlJ2rlz50XnnDp1qk+nvMzkcDg0Z84cr4uu4X/02Rz02Rz02Rz02TwNodcN5j5AAAAAZgn6NUAAAABmIwABAADLIQABAADLIQABAADLIQCZ6Nlnn1ViYqKaNWumgQMHavfu3cEuqclZsGCBBgwYoOjoaMXExGjMmDEqKCgIdllN2sKFC2Wz2TR9+vRgl9IkHTlyRHfffbfatGmjiIgI9erVSx9//HGwy2pSqqurNXv2bHXq1EkRERHq3LmzHn/88Xo9Twp1e++99zR69GjFxcXJZrPptdde89puGIYeffRRxcbGKiIiQsOHD9eXX35pWn0EIJP86U9/UlZWlubMmaNPP/1Uffr0UWpqqo4fPx7s0pqUd999V06nUzt37lRubq5cLpdSUlJ05syZYJfWJOXn5+sPf/iDevfuHexSmqTvvvtOgwcPlt1u15tvvqn9+/frt7/9rVq1ahXs0pqUp556SsuWLdPSpUt14MABPfXUU3r66af1zDPPBLu0Ru3MmTPq06ePnn322Vq3P/300/rd736n5557Trt27VJUVJRSU1N17tw5cwo0YIqbbrrJcDqdnuXq6mojLi7OWLBgQRCravqOHz9uSDLefffdYJfS5Jw6dcro0qWLkZubawwdOtTIzMwMdklNTnZ2tvHjH/842GU0eaNGjTImTZrkte6nP/2pkZ6eHqSKmh5JxoYNGzzLbrfb6NChg7Fo0SLPurKyMsPhcBgvv/yyKTVxBMgElZWV+uSTTzR8+HDPupCQEA0fPlwfffRRECtr+k6ePClJat26dZAraXqcTqdGjRrl9d81/GvTpk3q37+/xo0bp5iYGPXt21fPP/98sMtqcgYNGqS3335bhYWFkqTPPvtM77//vkaMGBHkypquQ4cOqaSkxOvfjxYtWmjgwIGm/V4M+p2greDEiROqrq6u8TiO9u3b64svvghSVU2f2+3W9OnTNXjwYF1//fXBLqdJWbt2rT799FPl5+cHu5Qm7auvvtKyZcuUlZWlWbNmKT8/X9OmTVN4eLgyMjKCXV6T8fDDD6u8vFzdunVTaGioqqur9eSTTyo9PT3YpTVZJSUlklTr78UL2wKNAIQmy+l0at++fXr//feDXUqTcvjwYWVmZio3N1fNmjULdjlNmtvtVv/+/TV//nxJUt++fbVv3z4999xzBCA/euWVV7R69WqtWbNGPXv21J49ezR9+nTFxcXR5yaMU2AmaNu2rUJDQ3Xs2DGv9ceOHVOHDh2CVFXTNnXqVL3xxhvavn27rr766mCX06R88sknOn78uG688UaFhYUpLCxM7777rn73u98pLCxM1dXVwS6xyYiNjVWPHj281nXv3l3FxcVBqqhpeuihh/Twww9r/Pjx6tWrl37xi19oxowZWrBgQbBLa7Iu/O4L5u9FApAJwsPD1a9fP7399tuedW63W2+//baSkpKCWFnTYxiGpk6dqg0bNuidd95Rp06dgl1SkzNs2DDt3btXe/bs8bz69++v9PR07dmzR6GhocEusckYPHhwjds4FBYW6pprrglSRU3T2bNnFRLi/eswNDRUbrc7SBU1fZ06dVKHDh28fi+Wl5dr165dpv1e5BSYSbKyspSRkaH+/fvrpptu0pIlS3TmzBndc889wS6tSXE6nVqzZo02btyo6Ohoz7nkFi1aKCIiIsjVNQ3R0dE1rqmKiopSmzZtuNbKz2bMmKFBgwZp/vz5uuuuu7R7924tX75cy5cvD3ZpTcro0aP15JNPqmPHjurZs6f+93//V4sXL9akSZOCXVqjdvr0aR08eNCzfOjQIe3Zs0etW7dWx44dNX36dD3xxBPq0qWLOnXqpNmzZysuLk5jxowxp0BTvmsGwzAM45lnnjE6duxohIeHGzfddJOxc+fOYJfU5Eiq9ZWTkxPs0po0vgYfOK+//rpx/fXXGw6Hw+jWrZuxfPnyYJfU5JSXlxuZmZlGx44djWbNmhnXXnut8etf/9qoqKgIdmmN2vbt22v99zgjI8MwjPNfhZ89e7bRvn17w+FwGMOGDTMKCgpMq89mGNzqEgAAWAvXAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAEAAMshAAFAPdhsNr322mvBLgOAnxCAADR4EydOlM1mq/G67bbbgl0agEaKh6ECaBRuu+025eTkeK1zOBxBqgZAY8cRIACNgsPhUIcOHbxerVq1knT+9NSyZcs0YsQIRURE6Nprr9W6deu83r93717deuutioiIUJs2bXT//ffr9OnTXmNWrlypnj17yuFwKDY2VlOnTvXafuLECf3kJz9RZGSkunTpok2bNgV2pwEEDAEIQJMwe/ZsjR07Vp999pnS09M1fvx4HThwQJJ05swZpaamqlWrVsrPz9err76qvLw8r4CzbNkyOZ1O3X///dq7d682bdqkH/3oR16fMW/ePN111136/PPPNXLkSKWnp6u0tNTU/QTgJ6Y9dx4ALlNGRoYRGhpqREVFeb2efPJJwzAMQ5LxwAMPeL1n4MCBxuTJkw3DMIzly5cbrVq1Mk6fPu3ZvnnzZiMkJMQoKSkxDMMw4uLijF//+td11iDJeOSRRzzLp0+fNiQZb775pt/2E4B5uAYIQKNwyy23aNmyZV7rWrdu7flzUlKS17akpCTt2bNHknTgwAH16dNHUVFRnu2DBw+W2+1WQUGBbDabvvnmGw0bNuyiNfTu3dvz56ioKDVv3lzHjx+/3F0CEEQEIACNQlRUVI1TUv4SERFRr3F2u91r2Wazye12B6IkAAHGNUAAmoSdO3fWWO7evbskqXv37vrss8905swZz/YPPvhAISEhuu666xQdHa3ExES9/fbbptYMIHg4AgSgUaioqFBJSYnXurCwMLVt21aS9Oqrr6p///768Y9/rNWrV2v37t1asWKFJCk9PV1z5sxRRkaG5s6dq3/84x968MEH9Ytf/ELt27eXJM2dO1cPPPCAYmJiNGLECJ06dUoffPCBHnzwQXN3FIApCEAAGoW33npLsbGxXuuuu+46ffHFF5LOf0Nr7dq1mjJlimJjY/Xyyy+rR48ekqTIyEht3bpVmZmZGjBggCIjIzV27FgtXrzYM1dGRobOnTun//qv/9KvfvUrtW3bVj/72c/M20EAprIZhmEEuwgAuBI2m00bNmzQmDFjgl0KgEaCa4AAAIDlEIAAAIDlcA0QgEaPM/kAfMURIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDn/D338L+k+ligCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Price]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy9klEQVR4nO3deXRTdd7H8U/apukiZSu0FMomDKssgiDghhQQFMRxF6WgwkGpgh11QGXfFLAwIovwiIzPg8LoAUWZ6QgVUAFBwSouVFARR2iBwTa0lTY09/nDQzS0YALJjeS+X+f0HPK79/7yvd9a8zl3i80wDEMAAAAWEhHqAgAAAMxGAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJYTFeoC/ojcbrcOHjyoatWqyWazhbocAADgA8MwdPz4caWkpCgi4uzHeAhAVTh48KBSU1NDXQYAADgHP/zwgxo0aHDWdQhAVahWrZqkXxqYkJAQ0LldLpfeeecd9enTR3a7PaBz41f02Rz02Rz02Rz02RzB7LPT6VRqaqrnc/xsCEBVOHXaKyEhISgBKC4uTgkJCfyBBRF9Ngd9Ngd9Ngd9NocZffbl8hUuggYAAJZDAAIAAJZDAAIAAJbDNUAAAJxFRUWFXC5XqMsIGy6XS1FRUTpx4oQqKir82tZutysyMjIgdRCAAACogmEYys/PV2FhYahLCSuGYSg5OVk//PDDOT1rr0aNGkpOTj7v5/QRgAAAqMKp8FO3bl3FxcXxYNwAcbvdKi4u1kUXXfS7Dyv8LcMwVFpaqsOHD0uS6tWrd151EIAAADhNRUWFJ/zUrl071OWEFbfbrfLycsXExPgVgCQpNjZWknT48GHVrVv3vE6HcRE0AACnOXXNT1xcXIgrwelO/U7O97osAhAAAGfAaa8/nkD9TghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAAD4wDAMlZafDMmPYRh+1Zqdna0rrrhCNWrUUO3atXXDDTfom2++kSRt2rRJNpvN6wnXubm5stls2r9/v2dsy5YtuuaaaxQXF6eaNWuqb9+++umnnwLRyj8EHoQIAIAPfnZVqPWEf4fkvb+c0ldx0b5/ZJeUlCgzM1Pt2rVTcXGxJkyYoJtuukm5ubk+bZ+bm6tevXrp3nvv1d/+9jdFRUVp48aNfn931x8ZAQgAgDBz8803e71etmyZ6tSpoy+//NKn7WfNmqXOnTtr4cKFnrE2bdoEtMZQIwABAOCDWHukvpzSN2Tv7Y+9e/dqwoQJ2r59u44ePSq32y1JOnDggE9Pt87NzdWtt956TrVeKAhAAAD4wGaz+XUaKpQGDBigRo0aaenSpUpJSZHb7Vbbtm1VXl6uiy66SJK8ris6/WslTn3nVjjjImgAAMLIf//7X+Xl5empp55Sr1691KpVK6+Ll+vUqSNJOnTokGfs9GuD2rVrp5ycHFPqDRUCEAAAYaRmzZqqXbu2lixZon379undd99VZmamZ3mzZs2UmpqqSZMmae/evVq3bp2effZZrznGjRunjz76SA8++KA+++wz7dmzR4sWLdLRo0fN3p2gIQABABBGIiIitHLlSu3cuVNt27bVI488otmzZ3uW2+12vfrqq9qzZ4/atWunZ555RtOmTfOa409/+pPeeecdffrpp+rSpYu6deumN998U1FRF8YpQF+Ez54AAABJUlpaWqU7vn57zU+PHj302WefnXG5JF199dXasmVL8IoMMY4AAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAj8aNG2vevHmhLiPoCEAAAMByCEAAAMByCEAAAPjCMKTyktD8nPZFpWeyZMkSpaSkyO12e43feOONuvfee/XNN9/oxhtvVFJSki666CJddtll2rBhwzm3JCsrS5dcconi4+OVmpqqBx98UMXFxZ7lkyZNUocOHby2+dvf/qZ27dp5jS1btkxt2rSRw+FQvXr1lJGRcc41+YpvgwcAwBeuUmlGSmje+4mDUnT8765266236qGHHtLGjRvVq1cvSdKxY8eUnZ2tf/7znyouLlb//v01ffp0ORwOvfzyyxowYIDy8vLUsGFDv8uKiIjQc889pyZNmujbb7/Vgw8+qMcff1wLFy70eY5FixYpMzNTTz/9tPr166eioiJTvoWeAAQAQJioWbOm+vXrp1deecUTgF5//XUlJiaqZ8+eioiIUPv27T3rT506VWvWrNHatWvP6ajLmDFjPP9u3Lixpk2bppEjR/oVgKZNm6a//OUvGj16tGfssssu87sWfxGAAADwhT3ulyMxoXpvHw0ePFjDhw/XwoUL5XA4tGLFCt1xxx2KiIhQcXGxJk2apHXr1unQoUM6efKkfv75Zx04cOCcytqwYYNmzpypPXv2yOl06uTJkzpx4oRKS0sVF/f7NR8+fFgHDx70hDUzEYAAAPCFzebTaahQGzBggAzD0Lp163TZZZfp/fff19y5cyVJjz76qNavX685c+aoWbNmio2N1S233KLy8nK/32f//v264YYb9MADD2j69OmqVauWPvjgA913330qLy9XXFycIiIiZJx2/ZLL5fL8OzY29vx29jwQgAAACCMxMTH685//rBUrVmjfvn1q0aKFLr30UknSli1bNHToUN10002SpOLiYu3fv/+c3mfnzp1yu9169tlnFRHxyz1V//jHP7zWqVOnjvLz82UYhmw2myQpNzfXs7xatWpq3LixcnJy1LNnz3Oq41wRgAAACDODBw/WDTfcoC+++EJ33323Z7x58+ZavXq1BgwYIJvNpvHjx1e6Y8xXzZo1k8vl0vz58zVgwABt2bJFixcv9lrnmmuu0ZEjRzRr1izdcsstys7OVnZ2ti666CLPOpMmTdLIkSNVt25d9evXT8ePH9eWLVv00EMPndvO+4jb4AEACDPXXnutatWqpby8PN11112e8aysLNWsWVPdu3fXgAED1LdvX8/RIX+1b99eWVlZeuaZZ9S2bVutWLFCM2fO9FqnVatWWrhwoRYsWKD27dtrx44d+stf/uK1Tnp6uubNm6eFCxeqTZs2uuGGG7R3795zqskfNuP0k3OQ0+lU9erVVVRUpISEhIDO7XK59M9//lP9+/eX3W4P6Nz4FX02B302B302x2/7XFFRoe+++05NmjRRTExMqEsLK263W06nUwkJCZ5TZ/44ceLEGX83/nx+/yGOAC1YsECNGzdWTEyMunbtqh07dpxx3eXLl8tms3n9/LYBLpdLf/3rXz0PZkpJSdGQIUN08GCIrtwHAAB/OCEPQKtWrVJmZqYmTpyoXbt2qX379urbt68OHz58xm0SEhJ06NAhz8/333/vWVZaWqpdu3Zp/Pjx2rVrl1avXq28vDwNHDjQjN0BACAsrFixQhdddFGVP23atAl1eect5BdBZ2Vlafjw4Ro2bJgkafHixVq3bp2WLVumsWPHVrmNzWZTcnJylcuqV6+u9evXe409//zz6tKliw4cOHBOT7oEAMBqBg4cqK5du1a5LBxOxYY0AJWXl2vnzp0aN26cZywiIkJpaWnatm3bGbcrLi5Wo0aN5Ha7demll2rGjBlnTaNFRUWy2WyqUaNGlcvLyspUVlbmee10OiX9cjrtt88rCIRT8wV6Xnijz+agz+agz+b4bZ/dbrcMw1BFRcU53yV1oYuPj1fTpk3PuPxc+3Lq0mPDMM5pjoqKChmGoZMnT1b6m/DnbySkF0EfPHhQ9evX19atW9WtWzfP+OOPP67Nmzdr+/btlbbZtm2b9u7dq3bt2qmoqEhz5szRe++9py+++EINGjSotP6JEyfUo0cPtWzZUitWrKiyjkmTJmny5MmVxl955RWfnmQJAAgvNptN9erVU3JysqpVqxbqcvAbx48fV35+vg4dOlTpIYulpaW66667fLoI+oILQKdzuVxq1aqV7rzzTk2dOrXSsptvvln/+c9/tGnTpjM2o6ojQKmpqTp69GhQ7gJbv369evfuHRaHEP+o6LM56LM56LM5Tu9zQUGBnE6n6tSpo7i4OM+D/HB+DMNQSUmJ4uPj/eqpYRgqLS3VkSNHlJCQoKSkpErrOJ1OJSYm+hSAQnoKLDExUZGRkSooKPAaLygoOOM1Pqez2+3q2LGj9u3b5zXucrl022236fvvv9e777571kY4HA45HI4q5w7W/2yCOTd+RZ/NQZ/NQZ/NcarP9evXV2RkpI4ePRrqksKKYRj6+eefFRsbe06hsmbNmkpOTq5yW3/+PkIagKKjo9WpUyfl5ORo0KBBkn45p5iTk+Pzt9JWVFRo9+7d6t+/v2fsVPjZu3evNm7cqNq1awejfABAGDt1Gqxu3bpcfxVALpdL7733nq666iq/A73dbldkZGRA6gj5XWCZmZlKT09X586d1aVLF82bN08lJSWeu8KGDBmi+vXre54uOWXKFF1++eVq1qyZCgsLNXv2bH3//fe6//77Jf3S2FtuuUW7du3S22+/rYqKCuXn50uSatWqpejo6NDsKADgghQZGRmwD1380s+TJ08qJiYmpEc0Qx6Abr/9dh05ckQTJkxQfn6+OnTooOzsbM+5vQMHDng9KfKnn37S8OHDlZ+fr5o1a6pTp07aunWrWrduLUn68ccftXbtWklShw4dvN5r48aNuuaaa0zZLwAA8McV8gAkSRkZGWc85bVp0yav13PnztXcuXPPOFfjxo0rXRUOAADwWyF/EjQAAIDZCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByQh6AFixYoMaNGysmJkZdu3bVjh07zrju8uXLZbPZvH5iYmK81lm9erX69Omj2rVry2azKTc3N8h7AAAALjQhDUCrVq1SZmamJk6cqF27dql9+/bq27evDh8+fMZtEhISdOjQIc/P999/77W8pKREV1xxhZ555plglw8AAC5QUaF886ysLA0fPlzDhg2TJC1evFjr1q3TsmXLNHbs2Cq3sdlsSk5OPuOc99xzjyRp//79Aa8XAACEh5AFoPLycu3cuVPjxo3zjEVERCgtLU3btm0743bFxcVq1KiR3G63Lr30Us2YMUNt2rQ5r1rKyspUVlbmee10OiVJLpdLLpfrvOY+3an5Aj0vvNFnc9Bnc9Bnc9BncwSzz/7MGbIAdPToUVVUVCgpKclrPCkpSXv27KlymxYtWmjZsmVq166dioqKNGfOHHXv3l1ffPGFGjRocM61zJw5U5MnT640/s477yguLu6c5z2b9evXB2VeeKPP5qDP5qDP5qDP5ghGn0tLS31eN6SnwPzVrVs3devWzfO6e/fuatWqlV544QVNnTr1nOcdN26cMjMzPa+dTqdSU1PVp08fJSQknFfNp3O5XFq/fr169+4tu90e0LnxK/psDvpsDvpsDvpsjmD2+dQZHF+ELAAlJiYqMjJSBQUFXuMFBQVnvcbnt+x2uzp27Kh9+/adVy0Oh0MOh6PK+YP1RxDMufEr+mwO+mwO+mwO+myOYPTZn/lCdhdYdHS0OnXqpJycHM+Y2+1WTk6O11Ges6moqNDu3btVr169YJUJAADCUEhPgWVmZio9PV2dO3dWly5dNG/ePJWUlHjuChsyZIjq16+vmTNnSpKmTJmiyy+/XM2aNVNhYaFmz56t77//Xvfff79nzmPHjunAgQM6ePCgJCkvL0+SlJyc7PORJQAAEN5CGoBuv/12HTlyRBMmTFB+fr46dOig7Oxsz4XRBw4cUETErwepfvrpJw0fPlz5+fmqWbOmOnXqpK1bt6p169aeddauXesJUJJ0xx13SJImTpyoSZMmmbNjAADgDy3kF0FnZGQoIyOjymWbNm3yej137lzNnTv3rPMNHTpUQ4cODVB1AAAgHIX8qzAAAADMRgACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWE+XLSk6n0++JExIS/N4GAADADD4FoBo1ashms/k8qc1m09dff62mTZuec2EAAADB4lMAkqTXX39dtWrV+t31DMNQ//79z6soAACAYPIpADVq1EhXXXWVateu7dOkTZs2ld1uP6/CAAAAgsWnAPTdd9/5Nennn39+TsUAAACY4bzuAjtx4kSg6gAAADCN3wHI7XZr6tSpql+/vi666CJ9++23kqTx48frxRdfDHiBAAAAgeZ3AJo2bZqWL1+uWbNmKTo62jPetm1b/c///E9AiwMAAAgGvwPQyy+/rCVLlmjw4MGKjIz0jLdv31579uwJaHEAAADB4HcA+vHHH9WsWbNK4263Wy6XKyBFAQAABJPfAah169Z6//33K42//vrr6tixY0CKAgAACCafH4R4yoQJE5Senq4ff/xRbrdbq1evVl5enl5++WW9/fbbwagRAAAgoPw+AnTjjTfqrbfe0oYNGxQfH68JEyboq6++0ltvvaXevXsHo0YAAICA8vsIkCRdeeWVWr9+faBrAQAAMIXfR4A++ugjbd++vdL49u3b9fHHHwekKAAAgGDyOwCNGjVKP/zwQ6XxH3/8UaNGjQpIUQAAAMHkdwD68ssvdemll1Ya79ixo7788suAFAUAABBMfgcgh8OhgoKCSuOHDh1SVNQ5XVIEAABgKr8DUJ8+fTRu3DgVFRV5xgoLC/XEE09wFxgAALgg+H3IZs6cObrqqqvUqFEjz4MPc3NzlZSUpP/93/8NeIEAAACB5ncAql+/vj777DOtWLFCn376qWJjYzVs2DDdeeedstvtwagRAAAgoM7pop34+HiNGDEi0LUAAACYwqcAtHbtWvXr1092u11r164967oDBw4MSGEAAADB4lMAGjRokPLz81W3bl0NGjTojOvZbDZVVFQEqjYAAICg8CkAud3uKv8NAABwIfLrNniXy6VevXpp7969waoHAAAg6PwKQHa7XZ999lmwagEAADCF3w9CvPvuu/Xiiy8GoxYAAABT+H0b/MmTJ7Vs2TJt2LBBnTp1Unx8vNfyrKysgBUHAAAQDH4HoM8//9zzZahff/211zKbzRaYqgAAAILI7wC0cePGYNQBAABgGr8C0KpVq7R27VqVl5erV69eGjlyZLDqAgAACBqfA9CiRYs0atQoNW/eXLGxsVq9erW++eYbzZ49O5j1AQAABJzPd4E9//zzmjhxovLy8pSbm6u///3vWrhwYTBrAwAACAqfA9C3336r9PR0z+u77rpLJ0+e1KFDh4JSGAAAQLD4HIDKysq8bnmPiIhQdHS0fv7556AUBgAAECx+XQQ9fvx4xcXFeV6Xl5dr+vTpql69umfsXJ4DtGDBAs2ePVv5+flq37695s+fry5dulS57vLlyzVs2DCvMYfDoRMnTnheG4ahiRMnaunSpSosLFSPHj20aNEiNW/e3O/aAABA+PE5AF111VXKy8vzGuvevbu+/fZbz+tzeQ7QqlWrlJmZqcWLF6tr166aN2+e+vbtq7y8PNWtW7fKbRISErxqOf19Z82apeeee05///vf1aRJE40fP159+/bVl19+qZiYGL9rBAAA4cXnALRp06agFJCVlaXhw4d7juosXrxY69at07JlyzR27Ngqt7HZbEpOTq5ymWEYmjdvnp566indeOONkqSXX35ZSUlJeuONN3THHXcEZT98YbjdKi0u0klXmUqLi2S320NWS7hzuVz02QT02Rz02Rz02Ryn+my43SGtw+8HIQZSeXm5du7cqXHjxnnGIiIilJaWpm3btp1xu+LiYjVq1Ehut1uXXnqpZsyYoTZt2kiSvvvuO+Xn5ystLc2zfvXq1dW1a1dt27atygBUVlamsrIyz2un0ynpl1+Sy+U67/08pbS4SNX/drFulqTPAzYtzoA+m4M+m4M+m4M+m+NmSUevvlrVa9QK6Lz+fGb7FIAyMzM1derUSt/7dSbjxo3TY489plq1zr5jR48eVUVFhZKSkrzGk5KStGfPniq3adGihZYtW6Z27dqpqKhIc+bMUffu3fXFF1+oQYMGys/P98xx+pynlp1u5syZmjx5cqXxd955x+uap/N10lX2yx8XAAAWt3nzZkXZHQGds7S01Od1bYZhGL+3UmRkpPLz81WnTh2fJk1ISFBubq6aNm161vUOHjyo+vXra+vWrerWrZtn/PHHH9fmzZu1ffv2330vl8ulVq1a6c4779TUqVO1detW9ejRQwcPHlS9evU86912222y2WxatWpVpTmqOgKUmpqqo0ePKiEhwZdd9onhdsvpLNTmzZt19dVXyx4VGbC54c11soI+m4A+m4M+m4M+m+NUn6+7rr+iHYENQE6nU4mJiSoqKvrdz2+fjgAZhqE//elPPl/kXFJS4tN6iYmJioyMVEFBgdd4QUHBGa/xOZ3dblfHjh21b98+SfJsV1BQ4BWACgoK1KFDhyrncDgcclTxS7Db7QE/D1y9Ri1F2R2qXqMW55iDyOVy0WcT0Gdz0Gdz0GdznOpztMMR8D77M59PAeill17yu4jTT0FVJTo6Wp06dVJOTo4GDRokSXK73crJyVFGRoZP71NRUaHdu3erf//+kqQmTZooOTlZOTk5nsDjdDq1fft2PfDAA37vBwAACD8+BaDfPgE60DIzM5Wenq7OnTurS5cumjdvnkpKSjx3hQ0ZMkT169fXzJkzJUlTpkzR5ZdfrmbNmqmwsFCzZ8/W999/r/vvv1/SL3eIjRkzRtOmTVPz5s09t8GnpKR4QhYAALC2kN4FJkm33367jhw5ogkTJig/P18dOnRQdna25wjSgQMHFBHx6wOrf/rpJw0fPlz5+fmqWbOmOnXqpK1bt6p169aedR5//HGVlJRoxIgRKiws1BVXXKHs7GyeAQQAACT9AQKQJGVkZJzxlNfpzx+aO3eu5s6de9b5bDabpkyZoilTpgSqRAAAEEZ8/i4wAACAcEEAAgAAluNXAHK5XIqKitLnn/OYTAAAcOHyKwDZ7XY1bNhQFRUVwaoHAAAg6Pw+Bfbkk0/qiSee0LFjx4JRDwAAQND5fRfY888/r3379iklJUWNGjWq9P1gu3btClhxAAAAweB3AOJhggAA4ELndwCaOHFiMOoAAAAwzTk/CHHnzp366quvJElt2rRRx44dA1YUAABAMPkdgA4fPqw77rhDmzZtUo0aNSRJhYWF6tmzp1auXKk6deoEukYAAICA8vsusIceekjHjx/XF198oWPHjunYsWP6/PPP5XQ69fDDDwejRgAAgIDy+whQdna2NmzYoFatWnnGWrdurQULFqhPnz4BLQ4AACAY/D4C5Ha7ZbfbK43b7Xa53e6AFAUAABBMfgega6+9VqNHj9bBgwc9Yz/++KMeeeQR9erVK6DFAQAABIPfAej555+X0+lU48aNdfHFF+viiy9WkyZN5HQ6NX/+/GDUCAAAEFB+XwOUmpqqXbt2acOGDdqzZ48kqVWrVkpLSwt4cQAAAMHgVwByuVyKjY1Vbm6uevfurd69ewerLgAAgKDh2+ABAIDl8G3wAADAcvg2eAAAYDl8GzwAALAcvwLQyZMnZbPZdO+996pBgwbBqgkAACCo/LoGKCoqSrNnz9bJkyeDVQ8AAEDQndOToDdv3hyMWgAAAEzh9zVA/fr109ixY7V792516tSp0kXQAwcODFhxAAAAweB3AHrwwQclSVlZWZWW2Ww2nhEEAAD+8PwOQHzjOwAAuND5fQ0QAADAhc7nANS/f38VFRV5Xj/99NMqLCz0vP7vf/+r1q1bB7Q4AACAYPA5AP373/9WWVmZ5/WMGTO8vg7j5MmTysvLC2x1AAAAQeBzADIM46yvAQAALhRcAwQAACzH5wBks9lks9kqjQEAAFxofL4N3jAMDR06VA6HQ5J04sQJjRw50vMgxN9eHwQAAPBH5nMASk9P93p99913V1pnyJAh518RAABAkPkcgF566aVg1gEAAGAaLoIGAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWE/IAtGDBAjVu3FgxMTHq2rWrduzY4dN2K1eulM1m06BBg7zGCwoKNHToUKWkpCguLk7XXXed9u7dG4TKAQDAhSqkAWjVqlXKzMzUxIkTtWvXLrVv3159+/bV4cOHz7rd/v379eijj+rKK6/0GjcMQ4MGDdK3336rN998U5988okaNWqktLQ0lZSUBHNXAADABSSkASgrK0vDhw/XsGHD1Lp1ay1evFhxcXFatmzZGbepqKjQ4MGDNXnyZDVt2tRr2d69e/Xhhx9q0aJFuuyyy9SiRQstWrRIP//8s1599dVg7w4AALhARIXqjcvLy7Vz506NGzfOMxYREaG0tDRt27btjNtNmTJFdevW1X333af333/fa1lZWZkkKSYmxmtOh8OhDz74QPfff3+Vc5aVlXm2lSSn0ylJcrlccrlc/u/cWZyaL9Dzwht9Ngd9Ngd9Ngd9Nkcw++zPnCELQEePHlVFRYWSkpK8xpOSkrRnz54qt/nggw/04osvKjc3t8rlLVu2VMOGDTVu3Di98MILio+P19y5c/Wf//xHhw4dOmMtM2fO1OTJkyuNv/POO4qLi/N9p/ywfv36oMwLb/TZHPTZHPTZHPTZHMHoc2lpqc/rhiwA+ev48eO65557tHTpUiUmJla5jt1u1+rVq3XfffepVq1aioyMVFpamvr16yfDMM4497hx45SZmel57XQ6lZqaqj59+ighISGg++FyubR+/Xr17t1bdrs9oHPjV/TZHPTZHPTZHPTZHMHs86kzOL4IWQBKTExUZGSkCgoKvMYLCgqUnJxcaf1vvvlG+/fv14ABAzxjbrdbkhQVFaW8vDxdfPHF6tSpk3Jzc1VUVKTy8nLVqVNHXbt2VefOnc9Yi8PhkMPhqDRut9uD9kcQzLnxK/psDvpsDvpsDvpsjmD02Z/5QnYRdHR0tDp16qScnBzPmNvtVk5Ojrp161Zp/ZYtW2r37t3Kzc31/AwcOFA9e/ZUbm6uUlNTvdavXr266tSpo7179+rjjz/WjTfeGPR9AgAAF4aQngLLzMxUenq6OnfurC5dumjevHkqKSnRsGHDJElDhgxR/fr1NXPmTMXExKht27Ze29eoUUOSvMZfe+011alTRw0bNtTu3bs1evRoDRo0SH369DFtvwAAwB9bSAPQ7bffriNHjmjChAnKz89Xhw4dlJ2d7bkw+sCBA4qI8O8g1aFDh5SZmamCggLVq1dPQ4YM0fjx44NRPgAAuECF/CLojIwMZWRkVLls06ZNZ912+fLllcYefvhhPfzwwwGoDAAAhKuQfxUGAACA2QhAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAckIegBYsWKDGjRsrJiZGXbt21Y4dO3zabuXKlbLZbBo0aJDXeHFxsTIyMtSgQQPFxsaqdevWWrx4cRAqBwAAF6qQBqBVq1YpMzNTEydO1K5du9S+fXv17dtXhw8fPut2+/fv16OPPqorr7yy0rLMzExlZ2fr//7v//TVV19pzJgxysjI0Nq1a4O1GwAA4AITFco3z8rK0vDhwzVs2DBJ0uLFi7Vu3TotW7ZMY8eOrXKbiooKDR48WJMnT9b777+vwsJCr+Vbt25Venq6rrnmGknSiBEj9MILL2jHjh0aOHBglXOWlZWprKzM89rpdEqSXC6XXC7Xee6lt1PzBXpeeKPP5qDP5qDP5qDP5ghmn/2Z02YYhhHwCnxQXl6uuLg4vf76616nsdLT01VYWKg333yzyu0mTpyozz77TGvWrNHQoUNVWFioN954w7N8xIgR+uSTT/TGG28oJSVFmzZt0sCBA7Vu3TpdddVVVc45adIkTZ48udL4K6+8ori4uPPaTwAAYI7S0lLdddddKioqUkJCwlnXDdkRoKNHj6qiokJJSUle40lJSdqzZ0+V23zwwQd68cUXlZube8Z558+frxEjRqhBgwaKiopSRESEli5desbwI0njxo1TZmam57XT6VRqaqr69Onzuw30l8vl0vr169W7d2/Z7faAzo1f0Wdz0Gdz0Gdz0GdzBLPPp87g+CKkp8D8cfz4cd1zzz1aunSpEhMTz7je/Pnz9eGHH2rt2rVq1KiR3nvvPY0aNUopKSlKS0urchuHwyGHw1Fp3G63B+2PIJhz41f02Rz02Rz02Rz02RzB6LM/84UsACUmJioyMlIFBQVe4wUFBUpOTq60/jfffKP9+/drwIABnjG32y1JioqKUl5enlJSUvTEE09ozZo1uv766yVJ7dq1U25urubMmXPGAAQAAKwlZHeBRUdHq1OnTsrJyfGMud1u5eTkqFu3bpXWb9mypXbv3q3c3FzPz8CBA9WzZ0/l5uYqNTXVc9FyRIT3bkVGRnrCEgAAQEhPgWVmZio9PV2dO3dWly5dNG/ePJWUlHjuChsyZIjq16+vmTNnKiYmRm3btvXavkaNGpLkGY+OjtbVV1+txx57TLGxsWrUqJE2b96sl19+WVlZWabuGwAA+OMKaQC6/fbbdeTIEU2YMEH5+fnq0KGDsrOzPRdGHzhwoNLRnN+zcuVKjRs3ToMHD9axY8fUqFEjTZ8+XSNHjgzGLgAAgAtQyC+CzsjIUEZGRpXLNm3adNZtly9fXmksOTlZL730UgAqAwAA4SrkX4UBAABgNgIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwnKhQF/BHZBiGJMnpdAZ8bpfLpdLSUjmdTtnt9oDPj1/QZ3PQZ3PQZ3PQZ3MEs8+nPrdPfY6fDQGoCsePH5ckpaamhrgSAADgr+PHj6t69epnXcdm+BKTLMbtduvgwYOqVq2abDZbQOd2Op1KTU3VDz/8oISEhIDOjV/RZ3PQZ3PQZ3PQZ3MEs8+GYej48eNKSUlRRMTZr/LhCFAVIiIi1KBBg6C+R0JCAn9gJqDP5qDP5qDP5qDP5ghWn3/vyM8pXAQNAAAshwAEAAAshwBkMofDoYkTJ8rhcIS6lLBGn81Bn81Bn81Bn83xR+kzF0EDAADL4QgQAACwHAIQAACwHAIQAACwHAIQAACwHAKQiRYsWKDGjRsrJiZGXbt21Y4dO0JdUliZOXOmLrvsMlWrVk1169bVoEGDlJeXF+qywt7TTz8tm82mMWPGhLqUsPTjjz/q7rvvVu3atRUbG6tLLrlEH3/8cajLCisVFRUaP368mjRpotjYWF188cWaOnWqT98nhTN77733NGDAAKWkpMhms+mNN97wWm4YhiZMmKB69eopNjZWaWlp2rt3r2n1EYBMsmrVKmVmZmrixInatWuX2rdvr759++rw4cOhLi1sbN68WaNGjdKHH36o9evXy+VyqU+fPiopKQl1aWHro48+0gsvvKB27dqFupSw9NNPP6lHjx6y2+3617/+pS+//FLPPvusatasGerSwsozzzyjRYsW6fnnn9dXX32lZ555RrNmzdL8+fNDXdoFraSkRO3bt9eCBQuqXD5r1iw999xzWrx4sbZv3674+Hj17dtXJ06cMKdAA6bo0qWLMWrUKM/riooKIyUlxZg5c2YIqwpvhw8fNiQZmzdvDnUpYen48eNG8+bNjfXr1xtXX321MXr06FCXFHb++te/GldccUWoywh7119/vXHvvfd6jf35z382Bg8eHKKKwo8kY82aNZ7XbrfbSE5ONmbPnu0ZKywsNBwOh/Hqq6+aUhNHgExQXl6unTt3Ki0tzTMWERGhtLQ0bdu2LYSVhbeioiJJUq1atUJcSXgaNWqUrr/+eq//rhFYa9euVefOnXXrrbeqbt266tixo5YuXRrqssJO9+7dlZOTo6+//lqS9Omnn+qDDz5Qv379QlxZ+Pruu++Un5/v9f+P6tWrq2vXrqZ9LvJlqCY4evSoKioqlJSU5DWelJSkPXv2hKiq8OZ2uzVmzBj16NFDbdu2DXU5YWflypXatWuXPvroo1CXEta+/fZbLVq0SJmZmXriiSf00Ucf6eGHH1Z0dLTS09NDXV7YGDt2rJxOp1q2bKnIyEhVVFRo+vTpGjx4cKhLC1v5+fmSVOXn4qllwUYAQlgaNWqUPv/8c33wwQehLiXs/PDDDxo9erTWr1+vmJiYUJcT1txutzp37qwZM2ZIkjp27KjPP/9cixcvJgAF0D/+8Q+tWLFCr7zyitq0aaPc3FyNGTNGKSkp9DmMcQrMBImJiYqMjFRBQYHXeEFBgZKTk0NUVfjKyMjQ22+/rY0bN6pBgwahLifs7Ny5U4cPH9all16qqKgoRUVFafPmzXruuecUFRWlioqKUJcYNurVq6fWrVt7jbVq1UoHDhwIUUXh6bHHHtPYsWN1xx136JJLLtE999yjRx55RDNnzgx1aWHr1GdfKD8XCUAmiI6OVqdOnZSTk+MZc7vdysnJUbdu3UJYWXgxDEMZGRlas2aN3n33XTVp0iTUJYWlXr16affu3crNzfX8dO7cWYMHD1Zubq4iIyNDXWLY6NGjR6VHOXz99ddq1KhRiCoKT6WlpYqI8P44jIyMlNvtDlFF4a9JkyZKTk72+lx0Op3avn27aZ+LnAIzSWZmptLT09W5c2d16dJF8+bNU0lJiYYNGxbq0sLGqFGj9Morr+jNN99UtWrVPOeRq1evrtjY2BBXFz6qVatW6bqq+Ph41a5dm+utAuyRRx5R9+7dNWPGDN12223asWOHlixZoiVLloS6tLAyYMAATZ8+XQ0bNlSbNm30ySefKCsrS/fee2+oS7ugFRcXa9++fZ7X3333nXJzc1WrVi01bNhQY8aM0bRp09S8eXM1adJE48ePV0pKigYNGmROgabcawbDMAxj/vz5RsOGDY3o6GijS5cuxocffhjqksKKpCp/XnrppVCXFva4DT543nrrLaNt27aGw+EwWrZsaSxZsiTUJYUdp9NpjB492mjYsKERExNjNG3a1HjyySeNsrKyUJd2Qdu4cWOV/09OT083DOOXW+HHjx9vJCUlGQ6Hw+jVq5eRl5dnWn02w+BRlwAAwFq4BggAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAfGCz2fTGG2+EugwAAUIAAvCHN3ToUNlstko/1113XahLA3CB4stQAVwQrrvuOr300kteYw6HI0TVALjQcQQIwAXB4XAoOTnZ66dmzZqSfjk9tWjRIvXr10+xsbFq2rSpXn/9da/td+/erWuvvVaxsbGqXbu2RowYoeLiYq91li1bpjZt2sjhcKhevXrKyMjwWn706FHddNNNiouLU/PmzbV27drg7jSAoCEAAQgL48eP180336xPP/1UgwcP1h133KGvvvpKklRSUqK+ffuqZs2a+uijj/Taa69pw4YNXgFn0aJFGjVqlEaMGKHdu3dr7dq1atasmdd7TJ48Wbfddps+++wz9e/fX4MHD9axY8dM3U8AAWLa984DwDlKT083IiMjjfj4eK+f6dOnG4ZhGJKMkSNHem3TtWtX44EHHjAMwzCWLFli1KxZ0yguLvYsX7dunREREWHk5+cbhmEYKSkpxpNPPnnGGiQZTz31lOd1cXGxIcn417/+FbD9BGAergECcEHo2bOnFi1a5DVWq1Ytz7+7devmtaxbt27Kzc2VJH311Vdq37694uPjPct79Oght9utvLw82Ww2HTx4UL169TprDe3atfP8Oz4+XgkJCTp8+PC57hKAECIAAbggxMfHVzolFSixsbE+rWe3271e22w2ud3uYJQEIMi4BghAWPjwww8rvW7VqpUkqVWrVvr0009VUlLiWb5lyxZFRESoRYsWqlatmho3bqycnBxTawYQOhwBAnBBKCsrU35+vtdYVFSUEhMTJUmvvfaaOnfurCuuuEIrVqzQjh079OKLL0qSBg8erIkTJyo9PV2TJk3SkSNH9NBDD+mee+5RUlKSJGnSpEkaOXKk6tatq379+un48ePasmWLHnroIXN3FIApCEAALgjZ2dmqV6+e11iLFi20Z88eSb/cobVy5Uo9+OCDqlevnl599VW1bt1akhQXF6d///vfGj16tC677DLFxcXp5ptvVlZWlmeu9PR0nThxQnPnztWjjz6qxMRE3XLLLebtIABT2QzDMEJdBACcD5vNpjVr1mjQoEGhLgXABYJrgAAAgOUQgAAAgOVwDRCACx5n8gH4iyNAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcv4fyjxLDOrYEDoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['auc'], label='auc')\n",
    "plt.plot(history.history['val_auc'], label='val_auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Price]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
